# Whole-Slide Image (WSI) Segmentation Pipeline

## Overview

This project implements an **end-to-end pipeline for semantic segmentation of whole-slide histopathology images (WSIs)**. It covers all major steps required for digital pathology workflows:

- **Tiling**: Splits multi-gigapixel WSI files into manageable image tiles.
- **Stain Normalization**: Reduces color variability across slides using reference tiles.
- **Data Augmentation**: Enhances dataset diversity for robust model training.
- **UNet Segmentation**: Deep learning-based semantic segmentation using the UNet architecture.
- **Stitching**: Combines tile-level predictions into a single segmented mask for the whole slide.
- **Evaluation**: Computes segmentation metrics (Dice score, etc.).

## Directory Structure

```
wsi-segmentation-pipeline/
├── data/
│   ├── raw_slides/           # Place WSI (.svs, .tif) files here
│   ├── processed_tiles/      # Tiles generated by tiling script
│   ├── masks/                # Ground-truth masks for training
│   ├── reference_tile.png    # Reference tile for normalization
├── notebooks/
│   └── wsi_pipeline_demo.ipynb
├── src/
│   ├── tiling.py
│   ├── stain_normalization.py
│   ├── augmentation.py
│   ├── unet_model.py
│   ├── train.py
│   ├── inference.py
│   ├── stitching.py
│   └── utils.py
├── requirements.txt
├── README.md
└── config.yaml (optional)
```

## Setup & Installation

1. **Clone the repository**  
   ```
   git clone <your-repo-url>
   cd wsi-segmentation-pipeline
   ```

2. **Install dependencies**  
   ```
   pip install -r requirements.txt
   ```

3. **Prepare your data**  
   - Download WSIs and masks from public datasets (see below).
   - Place files in the appropriate folders under `data/`.

## Public Example Datasets

- [CAMELYON16](https://camelyon16.grand-challenge.org/Data/) — Breast cancer lymph node WSIs + masks
- [MoNuSeg](https://monuseg.grand-challenge.org/Data/) — Nuclear segmentation tiles + masks
- [PanNuke](https://warwick.ac.uk/fac/sci/dcs/research/tia/pannuke) — Nuclear segmentation tiles + masks
- [TCGA Portal](https://portal.gdc.cancer.gov/) — Various cancer WSIs (registration required)

## Pipeline Steps

Each step can be run independently as a script or interactively via the provided Jupyter notebook.

### 1. **Tiling**
```python
from src.tiling import tile_wsi
tile_wsi('data/raw_slides/sample.svs', 'data/processed_tiles/', tile_size=1024, overlap=0)
```

### 2. **Stain Normalization**
```python
from src.stain_normalization import normalize_tiles
normalize_tiles('data/processed_tiles/', 'data/reference_tile.png', 'data/norm_tiles/')
```

### 3. **Augmentation**
```python
from src.augmentation import augment_tiles
augment_tiles('data/norm_tiles/', 'data/aug_tiles/', num_aug=5)
```

### 4. **Training**
```python
from src.train import train
model = train('data/aug_tiles/', 'data/masks/', epochs=10, batch_size=4, lr=1e-4, device='cuda')
```

### 5. **Inference**
```python
from src.inference import run_inference
run_inference('data/aug_tiles/', 'checkpoint_epoch10.pt', 'data/pred_masks/', device='cuda')
```

### 6. **Stitching**
```python
from src.stitching import stitch_masks
stitch_masks('data/pred_masks/', 'data/full_mask.png', (50000, 50000), tile_size=1024, overlap=0)
```

## Jupyter Demo

See `notebooks/wsi_pipeline_demo.ipynb` for an interactive walkthrough, including visualization.

## Notes

- **Adjust parameters and file paths** as needed for your data.
- For tile-based datasets (PanNuke, MoNuSeg), you can skip tiling.
- The pipeline is modular: run the steps you need.
- GPU recommended for training/inference (set `device='cuda'`).

## License

MIT License

---

**Contact / Issues:**  
Open an issue in this repository for any questions or help.
